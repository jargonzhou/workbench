{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ceebd7",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "* https://github.com/langchain-ai/langchain\n",
    "* how-to guides: https://python.langchain.com/docs/how_to/\n",
    "\n",
    "> LangChain is a framework for building LLM-powered applications. It helps you chain together interoperable components and third-party integrations to simplify AI application development — all while future-proofing decisions as the underlying technology evolves.\n",
    "\n",
    "tutorial: \n",
    "- [LangChain开发入门教程](https://github.com/QunBB/DeepLearning?tab=readme-ov-file#91-langchain) - [v0.1](https://python.langchain.com/v0.1/docs/get_started/introduction/)\n",
    "  - Model IO: prompts, llms, chat model, output parsers\n",
    "  - RAG: 文档加载, 文档分割, embedding, 向量数据库, 检索\n",
    "  - Tools/Agents: 工具, function call, agent\n",
    "- [LangChain 的中文入门教程](https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide) \n",
    "  - 必知概念\n",
    "  - 实战\n",
    "  - 小例子们"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc203ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Downloading langchain_core-0.3.60-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\software\\miniconda3\\lib\\site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\software\\miniconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\software\\miniconda3\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\software\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.18-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\software\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\software\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\software\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\software\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\software\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\software\\miniconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in d:\\software\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\software\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in d:\\software\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\software\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\software\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (2.1)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.60-py3-none-any.whl (437 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "Downloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading orjson-3.10.18-cp312-cp312-win_amd64.whl (134 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, tenacity, pydantic-core, orjson, annotated-types, requests-toolbelt, pydantic, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed annotated-types-0.7.0 langchain-0.3.25 langchain-core-0.3.60 langchain-text-splitters-0.3.8 langsmith-0.3.42 orjson-3.10.18 pydantic-2.11.4 pydantic-core-2.33.2 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspection-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "936bf77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-community) (0.3.60)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-community) (2.0.36)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-community) (0.3.42)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\software\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.4.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in d:\\software\\miniconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\software\\miniconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\software\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\software\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\software\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\software\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\software\\miniconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\software\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\software\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\software\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\software\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\software\\miniconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in d:\\software\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\software\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in d:\\software\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\software\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\software\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\software\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\software\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 6.6 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-win_amd64.whl (439 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-win_amd64.whl (120 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.4.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.0-cp312-cp312-win_amd64.whl (92 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: python-dotenv, propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 dataclasses-json-0.6.7 frozenlist-1.6.0 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 multidict-6.4.3 mypy-extensions-1.1.0 propcache-0.3.1 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0 yarl-1.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ac28b",
   "metadata": {},
   "source": [
    "# model: Ollama, DeepSeek\n",
    "* https://python.langchain.com/docs/integrations/chat/ollama/\n",
    "* API: https://python.langchain.com/api_reference/ollama/chat_models/langchain_ollama.chat_models.ChatOllama.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26717852",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cad3d293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in d:\\software\\miniconda3\\lib\\site-packages (0.4.8)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in d:\\software\\miniconda3\\lib\\site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in d:\\software\\miniconda3\\lib\\site-packages (from ollama) (2.11.4)\n",
      "Requirement already satisfied: anyio in d:\\software\\miniconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in d:\\software\\miniconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\software\\miniconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.6)\n",
      "Requirement already satisfied: idna in d:\\software\\miniconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in d:\\software\\miniconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\software\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\software\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\software\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\software\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\software\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "055bba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiation\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"deepseek-r1:7b\",\n",
    "    temperature=0.5,\n",
    "    num_predict=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a839ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nAlright, I need to translate \"I love programming.\" from English to Chinese. First, let\\'s break down each part of the sentence.\\n\\n\"I\" is straightforward; in Chinese, it can be translated as \"我.\"\\n\\n\"love\" means 爱 or 喜欢. Considering context, 爱 might be more appropriate here since it conveys a deeper affection towards programming.\\n\\n\"programming\" translates to 程序设计. This seems like the most accurate term for the technical field involved in coding.\\n\\nPutting it all together: \"我爱编程.\" This maintains the original sentiment and accurately reflects each word\\'s meaning.\\n</think>\\n\\n我爱编程。', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:7b', 'created_at': '2025-05-19T06:57:16.8304505Z', 'done': True, 'done_reason': 'stop', 'total_duration': 17436481600, 'load_duration': 45010600, 'prompt_eval_count': 23, 'prompt_eval_duration': 618280900, 'eval_count': 136, 'eval_duration': 16770343600, 'model_name': 'deepseek-r1:7b'}, id='run--609c91ac-c388-4d87-853d-75de4545d9ba-0', usage_metadata={'input_tokens': 23, 'output_tokens': 136, 'total_tokens': 159})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invocation\n",
    "# https://python.langchain.com/api_reference/ollama/chat_models/langchain_ollama.chat_models.ChatOllama.html#langchain_ollama.chat_models.ChatOllama.invoke\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to Chinese. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13d3ef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, I need to translate \"I love programming.\" into Chinese. The phrase is straightforward, so first, let's break it down.\n",
      "\n",
      "\"I\" in English corresponds to \"我\" in Chinese.\n",
      "\"love\" is \"爱\".\n",
      "\"programming\" can be translated as \"编程\".\n",
      "\n",
      "Putting it together: 我爱编程.\n",
      "\n",
      "That should capture the meaning accurately and naturally.\n",
      "</think>\n",
      "\n",
      "我爱编程。\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b0b7d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, so I need to translate the sentence \"I love programming.\" into German. Let me think about how to approach this.\\n\\nFirst, breaking down the sentence: \"I\" is the subject, \"love\" is the verb, and \"programming\" is the object. In German, pronouns are case-sensitive, so \"ich\" would be used for \"I\". \\n\\nNext, looking at the verb \"love.\" The infinitive form in German is usually formed with \"-en,\" but I also know that some verbs have irregular conjugations. For \"to love,\" the present tense is \"leben,\" right? So \"ich lebe\" would mean \"I love.\"\\n\\nNow, for the object \"programming.\" In German, nouns often take an adjective form when used as objects in the prepositional case (dative). The adjective form of \"programmieren\" (to program) is \"programmiert.\" So, putting it together, after \"ich lebe,\" I would add \"programmiert.\"\\n\\nPutting it all together: \"Ich love programming.\" becomes \"Ich lebe programmiert.\"\\n\\nWait, but I should double-check the verb conjugation. Sometimes in German, verbs can have different forms depending on gender or other factors. However, \"love\" is a simple verb and its present tense form for the subject \"ich\" is indeed \"leben,\" so that part seems correct.\\n\\nAlso, considering the noun case: \"programming\" is a countable noun, so it should be in nominative case when used after the verb. So yes, \"programmiert\" is the correct adjective form to use as an object.\\n\\nI don\\'t think I\\'m missing anything else here. The translation seems straightforward because both parts are pretty direct translations without any complex word changes.\\n\\nSo, finalizing my thought process: \"Ich love programming.\" translates to \"Ich lebe programmiert.\" in German.\\n</think>\\n\\nIch lebe programmiert.', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:7b', 'created_at': '2025-05-19T06:55:12.1237561Z', 'done': True, 'done_reason': 'stop', 'total_duration': 52169261300, 'load_duration': 44413900, 'prompt_eval_count': 18, 'prompt_eval_duration': 411866600, 'eval_count': 401, 'eval_duration': 51711533100, 'model_name': 'deepseek-r1:7b'}, id='run--911910fc-b692-407c-8cbb-453a75a84a51-0', usage_metadata={'input_tokens': 18, 'output_tokens': 401, 'total_tokens': 419})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain model with a prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14cc80f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to translate the sentence \"I love programming.\" into German. Let me think about how to approach this.\n",
      "\n",
      "First, understanding each part of the sentence is key. The subject here is \"I,\" which in German would be \"ich.\" Then comes the verb phrase \"love programming.\" In German, verbs often change based on subject pronouns and tenses. Since there's no tense specified, I'll assume it's the present tense.\n",
      "\n",
      "The word \"love\" translates to \"liebe.\" Now, for \"programming,\" that can be a noun or part of an infinitive verb. If we're talking about programming as an activity, using it as a noun would require a preposition like \"mit\" (with) or \"über\" (over). So maybe \"Ich love programming with passion.\" But if I just want to say I enjoy the act itself without necessarily doing something with it, then \"ich love to program\" might be better.\n",
      "\n",
      "Wait, but in German, verbs often take an infinitive form for certain constructions. If I structure it as \"I love programming,\" it could be phrased as \"Ich liebe Programming.\" But that feels a bit off because \"programmieren\" is the verb here. So perhaps the correct way is to conjugate the verb properly.\n",
      "\n",
      "Alternatively, if we use \"to program\" as an infinitive, it would be \"ich love zu programmieren.\" That makes sense grammatically: \"Ich love zu programmieren.\"\n",
      "\n",
      "But maybe using a noun instead of the infinitive might be more natural. So, \"programmieren\" could be used with a preposition. For example, \"Ich love mit programmieren,\" which means \"I love to program.\" Or \"Ich love über Programmieren,\" meaning \"I love programming over something else.\"\n",
      "\n",
      "Wait, but in English, we often say \"I love programming\" without any additional context, so the simplest translation would be \"ich liebe Programmieren.\" But I've heard people use \"zu programmieren\" as a gerundive form. So maybe \"ich love zu programmieren\" is more accurate.\n",
      "\n",
      "Alternatively, if considering a different structure, like \"I love that you program,\" it could be \"Ich love, dass du programmierst.\" But that's adding extra context which wasn't in the original sentence.\n",
      "\n",
      "So perhaps the best translation without additional context would be \"Ich liebe Programmieren.\" Or maybe \"Ich love zu programmieren.\"\n",
      "\n",
      "Let me check some examples. If someone says \"I love programming,\" it could be translated as \"Ich love zu programmieren\" because \"to program\" is a common infinitive used in this way.\n",
      "\n",
      "But I'm not entirely sure if \"liebe\" is the right verb here or if another verb like \"appreciere\" (appreciate) might be more appropriate. However, \"love\" translates directly to \"liebe,\" so it's correct to use that.\n",
      "\n",
      "So putting it all together, the translation would be either \"Ich liebe Programmieren.\" or \"Ich love zu programmieren.\"\n",
      "\n",
      "I think the first one is simpler and more direct, so I'll go with \"Ich liebe Programmieren.\"\n",
      "</think>\n",
      "\n",
      "The translation of \"I love programming.\" into German is:\n",
      "\n",
      "\"Ich liebe Programmieren.\"\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70d049",
   "metadata": {},
   "source": [
    "# 应用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e5923",
   "metadata": {},
   "source": [
    "## 对超长文本进行总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95774b",
   "metadata": {},
   "source": [
    "pdf-to-text: [FreeConvert](https://www.freeconvert.com/pdf-to-text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02070c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\software\\miniconda3\\Lib\\site-packages\\~il'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-unstructured[local] in d:\\software\\miniconda3\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-unstructured[local]) (0.3.60)\n",
      "Requirement already satisfied: onnxruntime<=1.19.2,>=1.17.0 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-unstructured[local]) (1.19.2)\n",
      "Requirement already satisfied: unstructured-client<1,>=0.27.0 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-unstructured[local]) (0.35.0)\n",
      "Collecting unstructured<0.16.0,>=0.15.7 (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading unstructured-0.15.14-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (4.12.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in d:\\software\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (2.11.4)\n",
      "Requirement already satisfied: coloredlogs in d:\\software\\miniconda3\\lib\\site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured[local]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\software\\miniconda3\\lib\\site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured[local]) (25.2.10)\n",
      "Requirement already satisfied: numpy>=1.21.6 in d:\\software\\miniconda3\\lib\\site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured[local]) (1.26.4)\n",
      "Requirement already satisfied: protobuf in d:\\software\\miniconda3\\lib\\site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured[local]) (5.28.3)\n",
      "Requirement already satisfied: sympy in d:\\software\\miniconda3\\lib\\site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured[local]) (1.14.0)\n",
      "Requirement already satisfied: chardet in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (5.2.0)\n",
      "Requirement already satisfied: filetype in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.4.27)\n",
      "Requirement already satisfied: lxml in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (5.4.0)\n",
      "Requirement already satisfied: nltk in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (3.9.1)\n",
      "Collecting tabulate (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: requests in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (4.12.3)\n",
      "Requirement already satisfied: emoji in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2.14.1)\n",
      "Requirement already satisfied: dataclasses-json in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2025.2.18)\n",
      "Requirement already satisfied: langdetect in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (3.13.0)\n",
      "Requirement already satisfied: backoff in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2.2.1)\n",
      "Requirement already satisfied: wrapt in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.17.2)\n",
      "Requirement already satisfied: tqdm in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (4.66.5)\n",
      "Requirement already satisfied: psutil in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (6.0.0)\n",
      "Requirement already satisfied: python-oxmsg in d:\\software\\miniconda3\\lib\\site-packages (from unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.0.2)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (43.0.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (1.6.0)\n",
      "Requirement already satisfied: pypdf>=4.0 in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (5.5.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (1.0.0)\n",
      "Requirement already satisfied: pdfminer.six in d:\\software\\miniconda3\\lib\\site-packages (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (20250506)\n",
      "Requirement already satisfied: google-cloud-vision in d:\\software\\miniconda3\\lib\\site-packages (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (3.10.1)\n",
      "Requirement already satisfied: networkx in d:\\software\\miniconda3\\lib\\site-packages (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (3.4.2)\n",
      "Requirement already satisfied: pi-heif in d:\\software\\miniconda3\\lib\\site-packages (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.22.0)\n",
      "Requirement already satisfied: pdf2image in d:\\software\\miniconda3\\lib\\site-packages (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.17.0)\n",
      "Requirement already satisfied: onnx in d:\\software\\miniconda3\\lib\\site-packages (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.18.0)\n",
      "Collecting python-pptx>=1.0.1 (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting python-docx>=1.1.2 (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: effdet in d:\\software\\miniconda3\\lib\\site-packages (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.4.1)\n",
      "Requirement already satisfied: markdown in d:\\software\\miniconda3\\lib\\site-packages (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (3.8)\n",
      "Requirement already satisfied: pikepdf in d:\\software\\miniconda3\\lib\\site-packages (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (9.7.0)\n",
      "Collecting unstructured-inference==0.7.36 (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading unstructured_inference-0.7.36-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in d:\\software\\miniconda3\\lib\\site-packages (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.3.15)\n",
      "Collecting openpyxl (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pypandoc (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading pypandoc-1.15-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: pandas in d:\\software\\miniconda3\\lib\\site-packages (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2.2.3)\n",
      "Collecting xlrd (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting layoutparser (from unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading layoutparser-0.3.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: python-multipart in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.0.20)\n",
      "Requirement already satisfied: huggingface-hub in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.31.2)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (4.11.0.86)\n",
      "Requirement already satisfied: matplotlib in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (3.9.2)\n",
      "Requirement already satisfied: torch in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2.7.0)\n",
      "Requirement already satisfied: timm in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.0.15)\n",
      "Requirement already satisfied: transformers>=4.25.1 in d:\\software\\miniconda3\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (4.51.3)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\software\\miniconda3\\lib\\site-packages (from cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (1.17.1)\n",
      "Requirement already satisfied: anyio in d:\\software\\miniconda3\\lib\\site-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in d:\\software\\miniconda3\\lib\\site-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\software\\miniconda3\\lib\\site-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (1.0.6)\n",
      "Requirement already satisfied: idna in d:\\software\\miniconda3\\lib\\site-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (3.7)\n",
      "Requirement already satisfied: sniffio in d:\\software\\miniconda3\\lib\\site-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\software\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\software\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\software\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (3.10.18)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\software\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\software\\miniconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\software\\miniconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\software\\miniconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-unstructured[local]) (0.4.0)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in d:\\software\\miniconda3\\lib\\site-packages (from python-pptx>=1.0.1->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (11.2.1)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx>=1.0.1->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\software\\miniconda3\\lib\\site-packages (from requests->unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\software\\miniconda3\\lib\\site-packages (from requests->unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2.2.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\software\\miniconda3\\lib\\site-packages (from beautifulsoup4->unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2.5)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\software\\miniconda3\\lib\\site-packages (from coloredlogs->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured[local]) (10.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\software\\miniconda3\\lib\\site-packages (from dataclasses-json->unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\software\\miniconda3\\lib\\site-packages (from dataclasses-json->unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.9.0)\n",
      "Requirement already satisfied: torchvision in d:\\software\\miniconda3\\lib\\site-packages (from effdet->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.22.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in d:\\software\\miniconda3\\lib\\site-packages (from effdet->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2.0.8)\n",
      "Requirement already satisfied: omegaconf>=2.0 in d:\\software\\miniconda3\\lib\\site-packages (from effdet->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2.3.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in d:\\software\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2.24.2)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in d:\\software\\miniconda3\\lib\\site-packages (from google-cloud-vision->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in d:\\software\\miniconda3\\lib\\site-packages (from google-cloud-vision->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.26.1)\n",
      "Requirement already satisfied: six in d:\\software\\miniconda3\\lib\\site-packages (from langdetect->unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.16.0)\n",
      "Requirement already satisfied: click in d:\\software\\miniconda3\\lib\\site-packages (from nltk->unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\software\\miniconda3\\lib\\site-packages (from nltk->unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\software\\miniconda3\\lib\\site-packages (from nltk->unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2024.11.6)\n",
      "Collecting et-xmlfile (from openpyxl->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\software\\miniconda3\\lib\\site-packages (from pandas->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\software\\miniconda3\\lib\\site-packages (from pandas->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\software\\miniconda3\\lib\\site-packages (from pandas->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2024.2)\n",
      "Requirement already satisfied: Deprecated in d:\\software\\miniconda3\\lib\\site-packages (from pikepdf->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.2.18)\n",
      "Requirement already satisfied: olefile in d:\\software\\miniconda3\\lib\\site-packages (from python-oxmsg->unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.47)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\software\\miniconda3\\lib\\site-packages (from sympy->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured[local]) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\software\\miniconda3\\lib\\site-packages (from tqdm->unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.4.6)\n",
      "Requirement already satisfied: pycparser in d:\\software\\miniconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain-unstructured[local]) (2.21)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\software\\miniconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.69.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\software\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\software\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\software\\miniconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\software\\miniconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\software\\miniconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (4.9)\n",
      "Requirement already satisfied: pyreadline3 in d:\\software\\miniconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured[local]) (3.5.4)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in d:\\software\\miniconda3\\lib\\site-packages (from omegaconf>=2.0->effdet->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (4.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\software\\miniconda3\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\software\\miniconda3\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\software\\miniconda3\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\software\\miniconda3\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\software\\miniconda3\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (3.2.0)\n",
      "Requirement already satisfied: safetensors in d:\\software\\miniconda3\\lib\\site-packages (from timm->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.5.3)\n",
      "Requirement already satisfied: filelock in d:\\software\\miniconda3\\lib\\site-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (3.16.1)\n",
      "Requirement already satisfied: jinja2 in d:\\software\\miniconda3\\lib\\site-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\software\\miniconda3\\lib\\site-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in d:\\software\\miniconda3\\lib\\site-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (75.2.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\software\\miniconda3\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.21.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\software\\miniconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured<0.16.0,>=0.15.7->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.1.0)\n",
      "Requirement already satisfied: scipy in d:\\software\\miniconda3\\lib\\site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (1.14.1)\n",
      "Collecting iopath (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pdfplumber (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\software\\miniconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (0.6.1)\n",
      "Collecting portalocker (from iopath->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\software\\miniconda3\\lib\\site-packages (from jinja2->torch->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (3.0.2)\n",
      "Collecting pdfminer.six (from unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local])\n",
      "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in d:\\software\\miniconda3\\lib\\site-packages (from pdfplumber->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (4.30.1)\n",
      "Requirement already satisfied: pywin32>=226 in d:\\software\\miniconda3\\lib\\site-packages (from portalocker->iopath->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]<0.16.0,>=0.15.7; python_version < \"3.13\" and extra == \"local\"->langchain-unstructured[local]) (307)\n",
      "Downloading unstructured-0.15.14-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading unstructured_inference-0.7.36-py3-none-any.whl (56 kB)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading pypandoc-1.15-py3-none-any.whl (21 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
      "   ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.4/19.2 MB 11.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 4.2/19.2 MB 10.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 7.9/19.2 MB 12.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 10.0/19.2 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 11.0/19.2 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 13.4/19.2 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 15.2/19.2 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 17.6/19.2 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.2/19.2 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 3.7/5.6 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.6 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: iopath\n",
      "  Building wheel for iopath (setup.py): started\n",
      "  Building wheel for iopath (setup.py): finished with status 'done'\n",
      "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31537 sha256=784240adeabe7e57595fb4cbda2da142ab2fedefbb5010335930057a457fc057\n",
      "  Stored in directory: c:\\users\\zhouj\\appdata\\local\\pip\\cache\\wheels\\7c\\96\\04\\4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n",
      "Successfully built iopath\n",
      "Installing collected packages: XlsxWriter, xlrd, tabulate, python-docx, pypandoc, portalocker, et-xmlfile, python-pptx, openpyxl, iopath, pdfminer.six, unstructured, pdfplumber, layoutparser, unstructured-inference\n",
      "  Attempting uninstall: pdfminer.six\n",
      "    Found existing installation: pdfminer.six 20250506\n",
      "    Uninstalling pdfminer.six-20250506:\n",
      "      Successfully uninstalled pdfminer.six-20250506\n",
      "  Attempting uninstall: unstructured\n",
      "    Found existing installation: unstructured 0.17.2\n",
      "    Uninstalling unstructured-0.17.2:\n",
      "      Successfully uninstalled unstructured-0.17.2\n",
      "  Attempting uninstall: unstructured-inference\n",
      "    Found existing installation: unstructured-inference 0.8.10\n",
      "    Uninstalling unstructured-inference-0.8.10:\n",
      "      Successfully uninstalled unstructured-inference-0.8.10\n",
      "Successfully installed XlsxWriter-3.2.3 et-xmlfile-2.0.0 iopath-0.1.10 layoutparser-0.3.4 openpyxl-3.1.5 pdfminer.six-20250327 pdfplumber-0.11.6 portalocker-3.1.1 pypandoc-1.15 python-docx-1.1.2 python-pptx-1.0.2 tabulate-0.9.0 unstructured-0.15.14 unstructured-inference-0.7.36 xlrd-2.0.1\n"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/integrations/document_loaders/unstructured_file/\n",
    "!pip install --upgrade --quiet langchain-unstructured unstructured-client unstructured \"unstructured[pdf]\" python-magic\n",
    "!pip install \"langchain-unstructured[local]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b9a0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: python-magic 0.4.27\n",
      "Uninstalling python-magic-0.4.27:\n",
      "  Successfully uninstalled python-magic-0.4.27\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/Yelp/elastalert/issues/1927\n",
    "!pip uninstall -y python-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad12b80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-magic-bin==0.4.14\n",
      "  Downloading python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl.metadata (710 bytes)\n",
      "Downloading python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl (409 kB)\n",
      "Installing collected packages: python-magic-bin\n",
      "Successfully installed python-magic-bin-0.4.14\n"
     ]
    }
   ],
   "source": [
    "!pip install python-magic-bin==0.4.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa5ef1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/how_to/recursive_text_splitter/\n",
    "!pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feeedbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to D:\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     D:\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/Unstructured-IO/unstructured/issues/3795\n",
    "# D:\\software\\miniconda3\\Lib\\site-packages\\unstructured\\nlp\\tokenize.py\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e5b1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents:1\n"
     ]
    }
   ],
   "source": [
    "# from langchain.document_loaders import UnstructuredFileLoader\n",
    "# from langchain_unstructured import UnstructuredLoader\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "\n",
    "# https://api.python.langchain.com/en/latest/langchain/chains/langchain.chains.summarize.chain.load_summarize_chain.html\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# from langchain import OpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 导入文本\n",
    "# loader = UnstructuredLoader([\"./data/LLMEngineersHandbook2024.txt\"])\n",
    "loader = TextLoader(\"./data/LLMEngineersHandbook2024.txt\")\n",
    "# 将文本转成 Document 对象\n",
    "document = loader.load()\n",
    "print(f'documents:{len(document)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2f7609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872657"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a455e97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents:190\n"
     ]
    }
   ],
   "source": [
    "# 初始化文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 5000,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "# 切分文本\n",
    "split_documents = text_splitter.split_documents(document)\n",
    "print(f'documents:{len(split_documents)}')\n",
    "\n",
    "# 加载 llm 模型\n",
    "# llm = OpenAI(model_name=\"text-davinci-003\", max_tokens=1500)\n",
    "llm = ChatOllama(\n",
    "    model=\"deepseek-r1:7b\",\n",
    "    temperature=0.5,\n",
    "    num_predict=None\n",
    ")\n",
    "\n",
    "# 创建总结链\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c29fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DPO has several advantages over traditional RLHF methods. As previously mentioned, it significantly simplifies the preference learning pipeline, reducing the engineering complexity associated\\nwith RLHF methods. By eliminating the need for a separate reward model and RL algorithms, DPO\\nis more computationally efficient than traditional RLHF approaches. Particularly when trained\\nwith adapters (LoRA, QLoRA), the frozen and trained models don’t have to be separated. Indeed,\\nsince we’re only training adapters, the trained model is not modified. This allows us to only load\\none model instead of two, which saves additional VRAM.\\nDespite its simplicity, DPO often matches the performance of more complex RLHF methods. It\\nalso tends to be more stable during training and less sensitive to hyperparameters. The simplified approach makes DPO easier to implement and scale, particularly for small teams without\\nextensive RL knowledge.\\n\\n250\\n\\nFine-Tuning with Preference Alignment\\n\\nWhile RLHF allows iterative improvement through multiple training rounds and can dynamically\\nadapt to new preferences, DPO offers a more straightforward path to achieving similar results.\\nThe choice between DPO and PPO-based RLHF often comes down to a trade-off between ease of\\nimplementation and potential peak performance. For large-scale training runs with millions of\\npreference samples, PPO-inspired methods still have a higher performance ceiling. However, for\\nmost applications, DPO provides the majority of the performance benefits at a lower computational and engineering cost.\\nBoth RLHF and DPO benefit significantly from the integration of synthetic data. As LLMs become\\nmore capable, they can generate data that surpasses human-created content in quality and diversity. This enables a virtuous cycle where better models produce better training data, which\\nin turn leads to further model improvements. The iterative nature of both approaches allows\\nmultiple rounds of model refinement, each focusing on different aspects of model performance\\nand gradually enhancing capabilities across various domains.\\nDespite its advantages, DPO is not without drawbacks. Like RLHF, DPO still requires paired preference data, which can be expensive and time-consuming to collect. DPO lacks some of the theoretical guarantees associated with reinforcement learning approaches. There may be scenarios\\nwhere the added flexibility of RLHF is beneficial, particularly for complex tasks or environments.\\nNonetheless, DPO is ideal in most cases, including our twin LLM example. In the next section,\\nwe will implement it using Unsloth.\\n\\nImplementing DPO\\nIn this section, we will DPO fine-tune the TwinLlama-3\\x081-8B model we created in Chapter 5. For\\nease of use and to maximize performance, we will again use the Unsloth library for our DPO implementation. Depending on the available VRAM, you can choose between LoRA (higher quality,\\nspeed, and VRAM usage) and QLoRA (lower quality, speed, and VRAM usage). This technique,\\nalong with other preference alignment algorithms, is also available in TRL and Axolotl.\\nThis example can be seen as an advanced application of DPO. Indeed, our objective of imitating\\na writing style conflicts with the natural tendency of DPO to encourage formal language. This is\\npartly due to the fact that chosen answers are often more formal than rejected ones. In practice,\\nthis will force us to do light fine-tuning, with a low learning rate and number of epochs. To find\\nthe best hyperparameters, we trained over 20 models and compared their outputs on a set of\\nquestions, including “Write a paragraph to introduce supervised fine-tuning.” This allowed us\\nto select the model and parameters that worked best for this task.\\n\\nChapter 6\\n\\n251\\n\\nThe dependencies are the same as those in Chapter 5 with SFT and can be found in the book’s\\nGitHub repository (https://github.com/PacktPublishing/LLM-Engineering) or in Unsloth’s\\nrepo (https://github.com/unslothai/unsloth):\\n1.\\n\\nFirst, we want to access a gated model and (optionally) upload our fine-tuned model to\\nHugging Face (https://huggingface.co/). This requires us to log in to an account. If\\nyou don’t have an account, you can create one and store your API key (Settings | Access\\nTokens | Create new token) in the .env file:\\nHF_TOKEN = YOUR_API_KEY\\n\\n2.\\n\\nMake sure that your Comet ML API key is also in the .env file. Otherwise, the code will\\ncrash and raise an error when training starts.\\nCOMET_API_KEY = YOUR_API_KEY\\n\\n3.\\n\\nBefore we import all the necessary packages, we want to apply a patch for the DPOTrainer\\nclass from TRL. This fixes the DPO logs in notebook environments.\\nfrom unsloth import PatchDPOTrainer\\nPatchDPOTrainer()\\n\\n4.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_documents[100].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a44e9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"DPO has several advantages over traditional RLHF methods. As previously mentioned, it significantly simplifies the preference learning pipeline, reducing the engineering complexity associated\n",
      "with RLHF methods. By eliminating the need for a separate reward model and RL algorithms, DPO\n",
      "is more computationally efficient than traditional RLHF approaches. Particularly when trained\n",
      "with adapters (LoRA, QLoRA), the frozen and trained models don’t have to be separated. Indeed,\n",
      "since we’re only training adapters, the trained model is not modified. This allows us to only load\n",
      "one model instead of two, which saves additional VRAM.\n",
      "Despite its simplicity, DPO often matches the performance of more complex RLHF methods. It\n",
      "also tends to be more stable during training and less sensitive to hyperparameters. The simplified approach makes DPO easier to implement and scale, particularly for small teams without\n",
      "extensive RL knowledge.\n",
      "\n",
      "250\n",
      "\n",
      "Fine-Tuning with Preference Alignment\n",
      "\n",
      "While RLHF allows iterative improvement through multiple training rounds and can dynamically\n",
      "adapt to new preferences, DPO offers a more straightforward path to achieving similar results.\n",
      "The choice between DPO and PPO-based RLHF often comes down to a trade-off between ease of\n",
      "implementation and potential peak performance. For large-scale training runs with millions of\n",
      "preference samples, PPO-inspired methods still have a higher performance ceiling. However, for\n",
      "most applications, DPO provides the majority of the performance benefits at a lower computational and engineering cost.\n",
      "Both RLHF and DPO benefit significantly from the integration of synthetic data. As LLMs become\n",
      "more capable, they can generate data that surpasses human-created content in quality and diversity. This enables a virtuous cycle where better models produce better training data, which\n",
      "in turn leads to further model improvements. The iterative nature of both approaches allows\n",
      "multiple rounds of model refinement, each focusing on different aspects of model performance\n",
      "and gradually enhancing capabilities across various domains.\n",
      "Despite its advantages, DPO is not without drawbacks. Like RLHF, DPO still requires paired preference data, which can be expensive and time-consuming to collect. DPO lacks some of the theoretical guarantees associated with reinforcement learning approaches. There may be scenarios\n",
      "where the added flexibility of RLHF is beneficial, particularly for complex tasks or environments.\n",
      "Nonetheless, DPO is ideal in most cases, including our twin LLM example. In the next section,\n",
      "we will implement it using Unsloth.\n",
      "\n",
      "Implementing DPO\n",
      "In this section, we will DPO fine-tune the TwinLlama-1-8B model we created in Chapter 5. For\n",
      "ease of use and to maximize performance, we will again use the Unsloth library for our DPO implementation. Depending on the available VRAM, you can choose between LoRA (higher quality,\n",
      "speed, and VRAM usage) and QLoRA (lower quality, speed, and VRAM usage). This technique,\n",
      "along with other preference alignment algorithms, is also available in TRL and Axolotl.\n",
      "This example can be seen as an advanced application of DPO. Indeed, our objective of imitating\n",
      "a writing style conflicts with the natural tendency of DPO to encourage formal language. This is\n",
      "partly due to the fact that chosen answers are often more formal than rejected ones. In practice,\n",
      "this will force us to do light fine-tuning, with a low learning rate and number of epochs. To find\n",
      "the best hyperparameters, we trained over 20 models and compared their outputs on a set of\n",
      "questions, including “Write a paragraph to introduce supervised fine-tuning.” This allowed us\n",
      "to select the model and parameters that worked best for this task.\n",
      "\n",
      "Chapter 6\n",
      "\n",
      "251\n",
      "\n",
      "The dependencies are the same as those in Chapter 5 with SFT and can be found in the book’s\n",
      "GitHub repository (https://github.com/PacktPublishing/LLM-Engineering) or in Unsloth’s\n",
      "repo (https://github.com/unslothai/unsloth):\n",
      "1.\n",
      "\n",
      "First, we want to access a gated model and (optionally) upload our fine-tuned model to\n",
      "Hugging Face (https://huggingface.co/). This requires us to log in to an account. If\n",
      "you don’t have an account, you can create one and store your API key (Settings | Access\n",
      "Tokens | Create new token) in the .env file:\n",
      "HF_TOKEN = YOUR_API_KEY\n",
      "\n",
      "2.\n",
      "\n",
      "Make sure that your Comet ML API key is also in the .env file. Otherwise, the code will\n",
      "crash and raise an error when training starts.\n",
      "COMET_API_KEY = YOUR_API_KEY\n",
      "\n",
      "3.\n",
      "\n",
      "Before we import all the necessary packages, we want to apply a patch for the DPOTrainer\n",
      "class from TRL. This fixes the DPO logs in notebook environments.\n",
      "from unsloth import PatchDPOTrainer\n",
      "PatchDPOTrainer()\n",
      "\n",
      "4.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input_documents': [Document(metadata={'source': './data/LLMEngineersHandbook2024.txt'}, page_content='DPO has several advantages over traditional RLHF methods. As previously mentioned, it significantly simplifies the preference learning pipeline, reducing the engineering complexity associated\\nwith RLHF methods. By eliminating the need for a separate reward model and RL algorithms, DPO\\nis more computationally efficient than traditional RLHF approaches. Particularly when trained\\nwith adapters (LoRA, QLoRA), the frozen and trained models don’t have to be separated. Indeed,\\nsince we’re only training adapters, the trained model is not modified. This allows us to only load\\none model instead of two, which saves additional VRAM.\\nDespite its simplicity, DPO often matches the performance of more complex RLHF methods. It\\nalso tends to be more stable during training and less sensitive to hyperparameters. The simplified approach makes DPO easier to implement and scale, particularly for small teams without\\nextensive RL knowledge.\\n\\n250\\n\\nFine-Tuning with Preference Alignment\\n\\nWhile RLHF allows iterative improvement through multiple training rounds and can dynamically\\nadapt to new preferences, DPO offers a more straightforward path to achieving similar results.\\nThe choice between DPO and PPO-based RLHF often comes down to a trade-off between ease of\\nimplementation and potential peak performance. For large-scale training runs with millions of\\npreference samples, PPO-inspired methods still have a higher performance ceiling. However, for\\nmost applications, DPO provides the majority of the performance benefits at a lower computational and engineering cost.\\nBoth RLHF and DPO benefit significantly from the integration of synthetic data. As LLMs become\\nmore capable, they can generate data that surpasses human-created content in quality and diversity. This enables a virtuous cycle where better models produce better training data, which\\nin turn leads to further model improvements. The iterative nature of both approaches allows\\nmultiple rounds of model refinement, each focusing on different aspects of model performance\\nand gradually enhancing capabilities across various domains.\\nDespite its advantages, DPO is not without drawbacks. Like RLHF, DPO still requires paired preference data, which can be expensive and time-consuming to collect. DPO lacks some of the theoretical guarantees associated with reinforcement learning approaches. There may be scenarios\\nwhere the added flexibility of RLHF is beneficial, particularly for complex tasks or environments.\\nNonetheless, DPO is ideal in most cases, including our twin LLM example. In the next section,\\nwe will implement it using Unsloth.\\n\\nImplementing DPO\\nIn this section, we will DPO fine-tune the TwinLlama-3\\x081-8B model we created in Chapter 5. For\\nease of use and to maximize performance, we will again use the Unsloth library for our DPO implementation. Depending on the available VRAM, you can choose between LoRA (higher quality,\\nspeed, and VRAM usage) and QLoRA (lower quality, speed, and VRAM usage). This technique,\\nalong with other preference alignment algorithms, is also available in TRL and Axolotl.\\nThis example can be seen as an advanced application of DPO. Indeed, our objective of imitating\\na writing style conflicts with the natural tendency of DPO to encourage formal language. This is\\npartly due to the fact that chosen answers are often more formal than rejected ones. In practice,\\nthis will force us to do light fine-tuning, with a low learning rate and number of epochs. To find\\nthe best hyperparameters, we trained over 20 models and compared their outputs on a set of\\nquestions, including “Write a paragraph to introduce supervised fine-tuning.” This allowed us\\nto select the model and parameters that worked best for this task.\\n\\nChapter 6\\n\\n251\\n\\nThe dependencies are the same as those in Chapter 5 with SFT and can be found in the book’s\\nGitHub repository (https://github.com/PacktPublishing/LLM-Engineering) or in Unsloth’s\\nrepo (https://github.com/unslothai/unsloth):\\n1.\\n\\nFirst, we want to access a gated model and (optionally) upload our fine-tuned model to\\nHugging Face (https://huggingface.co/). This requires us to log in to an account. If\\nyou don’t have an account, you can create one and store your API key (Settings | Access\\nTokens | Create new token) in the .env file:\\nHF_TOKEN = YOUR_API_KEY\\n\\n2.\\n\\nMake sure that your Comet ML API key is also in the .env file. Otherwise, the code will\\ncrash and raise an error when training starts.\\nCOMET_API_KEY = YOUR_API_KEY\\n\\n3.\\n\\nBefore we import all the necessary packages, we want to apply a patch for the DPOTrainer\\nclass from TRL. This fixes the DPO logs in notebook environments.\\nfrom unsloth import PatchDPOTrainer\\nPatchDPOTrainer()\\n\\n4.')], 'output_text': \"<think>\\nOkay, I need to write a concise summary of this provided text about DPO and its implementation using Unsloth. Let me start by reading through the entire text carefully.\\n\\nThe first part talks about DPO having advantages over traditional RLHF methods. It simplifies the pipeline by eliminating the need for a separate reward model and RL algorithms, which reduces computational complexity and VRAM usage. This makes it easier to implement, especially for smaller teams without deep RL knowledge. Despite its simplicity, DPO performs well and is more stable than complex methods.\\n\\nNext, there's a section on fine-tuning with preference alignment using PPO-based methods versus DPO. It mentions that while PPO can have higher performance ceilings, DPO offers better value in most cases due to lower computational costs without sacrificing much performance.\\n\\nThe text also discusses the use of synthetic data and the iterative nature of both approaches for model improvement. However, it notes that DPO lacks some theoretical guarantees compared to RLHF methods, which might be beneficial in certain complex scenarios.\\n\\nThen, the focus shifts to implementing DPO with Unsloth for fine-tuning a specific model (TwinLlama-3\\x081-8B). It mentions using LoRA or QLoRA based on VRAM availability. The example has some challenges due to the writing style preference, requiring light fine-tuning and careful hyperparameter selection after testing multiple models.\\n\\nThe dependencies are similar to Chapter 5 with SFT, so I should note that the setup involves accessing a gated model via Hugging Face and setting up API keys in a .env file. There's also a mention of applying a patch for DPOTrainer from TRL.\\n\\nPutting this all together, the summary needs to cover the advantages of DPO, its comparison with RLHF, implementation details with Unsloth, challenges faced, and necessary setup steps.\\n</think>\\n\\n**Summary:**\\n\\nDPO (Distributed Preference Optimization) offers significant advantages over traditional RLHF methods by simplifying the preference learning pipeline. It eliminates the need for separate reward models and RL algorithms, reducing computational complexity and VRAM usage, making it ideal for small teams without extensive RL expertise. Despite its simplicity, DPO performs well and is stable, often matching or exceeding complex RLHF methods in performance.\\n\\nThe implementation of DPO with Unsloth involves fine-tuning a model (TwinLlama-3\\x081-8B) using either LoRA or QLoRA, depending on VRAM availability. Challenges include the preference for formal writing styles, necessitating light fine-tuning and hyperparameter optimization. Setup requires accessing a gated model via Hugging Face and setting up API keys in a .env file. A patch for DPOTrainer from TRL is applied to ensure proper logging.\"}\n"
     ]
    }
   ],
   "source": [
    "# 执行总结链，（为了快速演示，只总结前5段）\n",
    "# chain.run(split_documents[:5])\n",
    "res = chain.invoke({\"input_documents\": split_documents[100:101]})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174a57da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to write a concise summary of this provided text about DPO and its implementation using Unsloth. Let me start by reading through the entire text carefully.\n",
      "\n",
      "The first part talks about DPO having advantages over traditional RLHF methods. It simplifies the pipeline by eliminating the need for a separate reward model and RL algorithms, which reduces computational complexity and VRAM usage. This makes it easier to implement, especially for smaller teams without deep RL knowledge. Despite its simplicity, DPO performs well and is more stable than complex methods.\n",
      "\n",
      "Next, there's a section on fine-tuning with preference alignment using PPO-based methods versus DPO. It mentions that while PPO can have higher performance ceilings, DPO offers better value in most cases due to lower computational costs without sacrificing much performance.\n",
      "\n",
      "The text also discusses the use of synthetic data and the iterative nature of both approaches for model improvement. However, it notes that DPO lacks some theoretical guarantees compared to RLHF methods, which might be beneficial in certain complex scenarios.\n",
      "\n",
      "Then, the focus shifts to implementing DPO with Unsloth for fine-tuning a specific model (TwinLlama-1-8B). It mentions using LoRA or QLoRA based on VRAM availability. The example has some challenges due to the writing style preference, requiring light fine-tuning and careful hyperparameter selection after testing multiple models.\n",
      "\n",
      "The dependencies are similar to Chapter 5 with SFT, so I should note that the setup involves accessing a gated model via Hugging Face and setting up API keys in a .env file. There's also a mention of applying a patch for DPOTrainer from TRL.\n",
      "\n",
      "Putting this all together, the summary needs to cover the advantages of DPO, its comparison with RLHF, implementation details with Unsloth, challenges faced, and necessary setup steps.\n",
      "</think>\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "DPO (Distributed Preference Optimization) offers significant advantages over traditional RLHF methods by simplifying the preference learning pipeline. It eliminates the need for separate reward models and RL algorithms, reducing computational complexity and VRAM usage, making it ideal for small teams without extensive RL expertise. Despite its simplicity, DPO performs well and is stable, often matching or exceeding complex RLHF methods in performance.\n",
      "\n",
      "The implementation of DPO with Unsloth involves fine-tuning a model (TwinLlama-1-8B) using either LoRA or QLoRA, depending on VRAM availability. Challenges include the preference for formal writing styles, necessitating light fine-tuning and hyperparameter optimization. Setup requires accessing a gated model via Hugging Face and setting up API keys in a .env file. A patch for DPOTrainer from TRL is applied to ensure proper logging.\n"
     ]
    }
   ],
   "source": [
    "print(res['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71a1546",
   "metadata": {},
   "source": [
    "Direct Preference Optimization (DPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9a87e",
   "metadata": {},
   "source": [
    "## 构建本地知识库问答机器人"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
