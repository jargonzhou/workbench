{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raft\n",
    "\n",
    "- [The Raft Consensus Algorithm - Web](https://raft.github.io/)\n",
    "- In Search of an Understandable Consensus Algorithm (Extended Version)\n",
    "\n",
    "reference implementation:\n",
    "- C++\n",
    "\t- [LogCabin](https://github.com/logcabin/logcabin)\n",
    "- Java\n",
    "\t- [Apache Ratis™](https://github.com/apache/ratis)\n",
    "\t- [SOFAJRaft](https://github.com/sofastack/sofa-jraft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "\n",
    "* [ref](https://zhuanlan.zhihu.com/p/32052223)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基础: 多副本状态机的日志复制.\n",
    "* 需要保证每个状态机以相同的顺序执行相同的命令.\n",
    "\n",
    "分解一致性问题为多个子问题:\n",
    "* Leader选举: Leader election\n",
    "* 日志复制: log replication\n",
    "* 安全性: safety\n",
    "* 日志压缩: log compaction\n",
    "* 成员变更: membership change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "术语:\n",
    "- term: 任期. 将时间划分为一个个任期. 每个任期的开始都是Leader选举.\n",
    "  - Leader选举成功: Leader在整个任期内管理.\n",
    "  - Leader选举失败: 该任期因没有Leader而结束.\n",
    "- heartbeat: 心跳\n",
    "- agreement: 协定, 意见一致, 同意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "角色:\n",
    "- Leader: 领导者.\n",
    "  - 接受客户端请求\n",
    "  - 向Follower同步请求日志, 当日志同步到大多数节点后让Follower提交日志\n",
    "- Follower: 跟从者\n",
    "  - 接受并持久化Leader同步的日志, 在Leader告知可以提交后提交日志.\n",
    "- Candidate: 候选人\n",
    "  - Leader选举过程中的临时角色\n",
    "\n",
    "约束: 任意时刻最多只能有一个Leader, 正常工作时只有Leader和Follower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leader选举\n",
    "\n",
    "- 初始化时均为Follower.\n",
    "  - 如果有Leader, Leader会向所有Follower周期性的发送heartbeat以维持其统治.\n",
    "  - 如果在**选举超时时间**内, 没有收到Leader的heartbeat, 等待随机的一段时间后, 将当前term+1并转换为Candidate, 发起一次Leader选举.\n",
    "- Candidate发起Leader选举: 给自己投票, 并给集群中的其他节点发送RequestVote.\n",
    "  - 情况(1): 赢得了多数的选票, 成为Leader. - **选举安全性**\n",
    "    - 约束: **选举约束**\n",
    "  - 情况(2): 收到Leader的heartbeat, 有其他节点当选了Leader.\n",
    "    - 如果该Leader的term >= 当前term: 合法的Leader, 切换到Follower状态.\n",
    "    - 如果该Leader的term < 当前term, 拒绝处理heartbeat, 保持在Candidate状态.\n",
    "  - 情况(3): 没有节点赢得多数的选票, Leader选举失败, 等待选举超时时间过后发起下一次选举.\n",
    "\n",
    "数据结构: heartbeat\n",
    "* 不带日志条目的AppendEntries.\n",
    "\n",
    "过程: 投票vote\n",
    "* 每个节点在指定任期内最多只投给一个Candidate, 按照FIFS(先到先服务)顺序.\n",
    "\n",
    "保证: 选举出的Leader上一定具有最新的已提交日志."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日志复制\n",
    "\n",
    "数据结构: 日志, 日志条目\n",
    "* 日志由有序编号的日志条目组成: log index\n",
    "* 每个日志条目包含: 创建时的term, 用于状态机执行的命令.\n",
    "  * 一个日志条目被复制到大多数节点上, 这时Leader决定将它应用到状态机中是安全的, 则被认为**可以提交committed**.\n",
    "\n",
    "过程:\n",
    "- Leader接受客户端的请求, 将请求作为日志条目Log Entry, 加入到日志中. - **日志只追加**\n",
    "- Leader并行的向其他节点发送AppendEntries以复制日志条目, 其他节点需要返回确认.\n",
    "  - 未返回确认的节点, Leader会无限次重试AppendEntries直到所有节点均返回确认.\n",
    "- 当该日志条目被复制到大多数节点上时, Leader将它**应用到状态机中**, 并向客户端返回执行结果.\n",
    "  - Leader记录**最新的已提交的日志条目commit index**, 并包含在之后的AppendEntries和heartbeat中. 一旦Follower知道日志条目已提交, 会将它应用到自己的状态机中.\n",
    "\n",
    "\n",
    "保证: - **日志匹配**\n",
    "* 如果不同日志中的两个条目有相同的log index和term, 则它们存储的命令是相同的.\n",
    "  * Leader在一个term内在一个log index上最多创建一个日志条目, 该日志条目在日志中的位置不会改变.\n",
    "* 如果不同日志中的两个条目有相同的log index和term, 则它们之前的所有条目都是相同的.\n",
    "  * **AppendEntries的一致性检查**: Leader会将紧邻新日志条目之前的条目的log index和term都包含在RPC请求中, 如果Follwer没有在日志中找到对应的log index和term都相同的日志条目, 则拒绝新的日志条目.\n",
    "  * **强制复制**: Leader找到Follower与它日志一致的地方(使用AppendEntries调用失败从后往前试), 然后覆盖Follower在该位置之后的条目.\n",
    "    * Leader维护每个Follower的nextIndex: 下一个发送的日志条目的log index. 初始值为它的下一个日志条目."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安全性\n",
    "\n",
    "* 选举安全性(Election Safety)\n",
    "  * 在指定term内, 最多选举出一个Leader\n",
    "* Leader只追加(Leader Append-Only)\n",
    "  * Leader从不覆盖或删除它的日志条目, 只追加新的条目.\n",
    "* 日志匹配(Log Matching)\n",
    "  * 如果两个日志中有term和log index相同的条目, 则这两个条目之前的日志条目均对应相同.\n",
    "* Leader完备性(Leader Completeness)\n",
    "  * 如果日志条目在指定term内被提交, 则该条目在所有后续term的Leader的日志中存在.\n",
    "* 状态机安全性(State Machine Safety)\n",
    "  * 如果一个服务器已经在特定log index上将日志条目应用到状态机中, 则其它服务器不会在相同的log index上应用不同的日志条目.\n",
    "\n",
    "机制:\n",
    "* **选举约束**: 拥有最新的已提交的日志条目的Follower才有资格成为Leader.\n",
    "  * Candidate发送RequestVote时, 要带上自己的最后一条日志的term和log index.\n",
    "  * 其他节点收到RequestVote后, 如果发现自己的日志比请求中携带的更新, 则拒绝投票.\n",
    "* **提交之前term的日志条目**: Leader只能推进commit index来提交当前term的已经复制到大多数节点的日志, **旧term日志的提交**要等到提交当前term的日志来间接提交.\n",
    "  * 否则会出现已提交的旧任期的日志条目被覆盖的情况. 例: paper Figure 8.\n",
    "\n",
    "数据操作: 日志条目比较\n",
    "* 如果term不相同: term大的更新; 否则\n",
    "* log index大的更新.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 成员变更\n",
    "\n",
    "数据结构: 集群配置(cluster configuration)\n",
    "* 参与共识算法的服务器/节点/成员的集合\n",
    "\n",
    "问题描述: \n",
    "* 集群运行过程中, 参与共识算法的服务器发生变化, 例如替换失败的服务器或修改副本数量等.\n",
    "* 特殊性: 在成员变更的一致性达成的过程中, 参与投票的节点也可能会发生变化. \n",
    "  * 例: paper Figure 10. 集群由3个节点增长为5个节点, 存在同一个任期中选举出两个Leader的情况, 一个有旧配置Cold的大多数支持, 一个有新配置Cnew的大多数支持.\n",
    "\n",
    "抽象: 联合共识(joint consensus)\n",
    "* 集群先切换到联合共识这个**过渡性的配置**; 一旦联合共识达成, 切换到新配置.\n",
    "* 联合共识组合了新旧配置:\n",
    "  * 日志条目复制到新旧配置中的所有服务器上;\n",
    "  * 新旧配置中任意服务器可以成为Leader;\n",
    "  * 协定(选举和日志条目提交)要求新旧配置中 **独立的大多数(seperate majorities)** 支持.\n",
    "\n",
    "过程:\n",
    "* Leader收到从Cold到Cnew的配置变更请求, 将联合共识的配置Cold,new作为日志条目存储, 并复制该日志条目.\n",
    "  * 一旦服务器将Cold,new添加到日志中, 就会在决策中使用该配置.\n",
    "* 一旦Cold,new被提交, Leader完备性属性保证只有复制了Cold,new日志条目的服务器被选举为Leader.\n",
    "  * **复制到Cold的大多数节点**, 且**复制到Cnew的大多数节点**时, 提交Cold,new.\n",
    "* Leader创建Cnew日志条目, 并在集群中复制.\n",
    "* 一旦Cnew被提交, 不在新配置中的服务器可以关闭.\n",
    "  * 复制到Cnew的大多数节点, 提交Cnew.\n",
    "* Leader响应成员变更结果.\n",
    "\n",
    "保证: 不会同时出现分别使用Cold和Cnew做决策的时间点. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日志压缩\n",
    "* 避免日志无限增长.\n",
    "* 每个节点独立的对日志执行snapshot, 只能对已提交的日志条目进行snapshot, snapshot之前的日志都可以丢弃.\n",
    "* Follower日志落后太多/新加节点: Leader发送InstalledSnapshot.\n",
    "\n",
    "数据结构: Snapshot\n",
    "* 日志元数据: 最后一条已提交的日志条目的term和log index. 用于snapshot之后的第一条日志条目的AppendEntries的完整性检查.\n",
    "* 系统当前状态."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper\n",
    "\n",
    "```\n",
    "1 Introduction\n",
    "2 Replicated state machines\n",
    "3 What’s wrong with Paxos?\n",
    "4 Designing for understandability\n",
    "5 The Raft consensus algorithm\n",
    "5.1 Raft basics\n",
    "5.2 Leader election\n",
    "5.3 Log replication\n",
    "5.4 Safety\n",
    "5.4.1 Election restriction\n",
    "5.4.2 Committing entries from previous terms\n",
    "5.4.3 Safety argument\n",
    "5.5 Follower and candidate crashes\n",
    "5.6 Timing and availability\n",
    "6 Cluster membership changes\n",
    "7 Log compaction\n",
    "8 Client interaction\n",
    "9 Implementation and evaluation\n",
    "9.1 Understandability\n",
    "9.2 Correctness\n",
    "9.3 Performance\n",
    "10 Related work\n",
    "11 Conclusion\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raft implements consensus by first electing a distinguished leader, then giving the leader complete responsibility for managing the replicated log.\n",
    "\n",
    "Given the leader approach, Raft decomposes the consensus problem into three relatively independent subproblems, which are discussed in the subsections that follow:\n",
    "\n",
    "- **Leader election**: a new leader must be chosen when an existing leader fails (Section 5.2).\n",
    "- **Log replication**: the leader must accept log entries from clients and replicate them across the cluster, forcing the other logs to agree with its own (Section 5.3).\n",
    "- **Safety**: the key safety property for Raft is the *State Machine Safety Property* in Figure 3: if any server has applied a particular log entry to its state machine, then no other server may apply a different command for the same log index. Section 5.4 describes how Raft ensures this property; the solution involves an additional restriction on the election mechanism described in Section 5.2.\n",
    "\n",
    "Figure 2: A condensed summary of the Raft consensus algorithm (excluding membership changes and log compaction). The server behavior in the upper-left box is described as a set of rules that trigger independently and repeatedly. Section numbers such as §5.2 indicate where particular features are discussed. \n",
    "A formal specification [31] describes the algorithm more precisely.\n",
    "\n",
    "Figure 3: Raft guarantees that each of these properties is true at all times. The section numbers indicate where each property is discussed.\n",
    "\n",
    "- **Election Safety**: *at most one leader* can be elected in a given term. §5.2\n",
    "- **Leader Append-Only**: a leader never overwrites or deletes entries in its log; it only *appends* new entries. §5.3\n",
    "- **Log Matching**: if two logs contain an entry with the same index and term, then the logs are identical in all entries *up through* the given index. §5.3\n",
    "- **Leader Completeness**: if a log entry is *committed* in a given term, then that entry will be present in the logs of the *leaders for all higher-numbered terms*. §5.4\n",
    "- **State Machine Safety**: if a server has *applied a log entry at a given index to its state machine*, no other server will ever apply a different log entry for the same index. §5.4.3\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
