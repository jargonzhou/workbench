{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubernetes\n",
    "- Doc: https://kubernetes.io/docs/\n",
    "  - [Kubernetes API](https://kubernetes.io/docs/reference/kubernetes-api/)\n",
    "- Code: https://github.com/kubernetes/kubernetes\n",
    "\n",
    "Books:\n",
    "* Lukša, Marko. **Kubernetes in Action**. 2017. Manning. [Kubernetes in Action.ipynb](./Kubernetes/Kubernetes%20in%20Action.ipynb)\n",
    "* 张磊. **深入剖析Kubernetes**. 2021. 人民邮电出版社.\n",
    "\n",
    "\n",
    "Topics:\n",
    "- 容器技术基础\n",
    "  - 隔离, 限制\n",
    "  - 容器运行时: CRI\n",
    "- 体系结构 \n",
    "- 集群部署\n",
    "  - kubeadm\n",
    "- 容器编排原理\n",
    "  - Pod\n",
    "  - Deployment\n",
    "  - StatefulSet\n",
    "  - DaemonSet\n",
    "  - Job, CronJob\n",
    "  - 声明式API\n",
    "  - RBAC\n",
    "  - Operator\n",
    "- 存储原理\n",
    "  - PV, PVC\n",
    "  - CSI插件\n",
    "- 网络原理\n",
    "  - 网络模型\n",
    "  - 三层网络方案\n",
    "  - CNI插件\n",
    "  - 网络隔离: NetworkPolicy\n",
    "  - Service\n",
    "  - Ingress\n",
    "- 调度与资源管理\n",
    "  - 资源模型\n",
    "  - 调度器: 调度策略, 优先级, 抢占\n",
    "  - Device Plugin\n",
    "- 监控与日志\n",
    "  - Metrics Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubernetes objects\n",
    "\n",
    "- Kubernetes objects\n",
    "\n",
    "Kubernetes objects are persistent entities in the Kubernetes system.\n",
    "A Kubernetes object is a \"record of intent\"--once you create the object, the Kubernetes system will constantly work to ensure that object exists.\n",
    "\n",
    "- Labels and Selectors\n",
    "\n",
    "Labels are key/value pairs that are attached to objects, such as pods. Labels are intended to be used to specify identifying attributes of objects that are meaningful and relevant to users, but do not directly imply semantics to the core system.\n",
    "\n",
    "Via a label selector, the client/user can identify a set of objects. The label selector is the core grouping primitive in Kubernetes.\n",
    "\n",
    "- Namespaces\n",
    "\n",
    "In Kubernetes, namespaces provides a mechanism for isolating groups of resources within a single cluster.\n",
    "\n",
    "- Annotations\n",
    "\n",
    "You can use Kubernetes annotations to attach arbitrary non-identifying metadata to objects. \n",
    "Clients such as tools and libraries can retrieve this metadata.\n",
    "\n",
    "- Field Selectors\n",
    "\n",
    "Field selectors let you select Kubernetes resources based on the value of one or more resource fields.\n",
    "\n",
    "- Finalizers\n",
    "\n",
    "Finalizers are namespaced keys that tell Kubernetes to wait until specific conditions are met before it fully deletes resources marked for deletion.\n",
    "\n",
    "- Owners and Dependents\n",
    "\n",
    "In Kubernetes, some objects are owners of other objects. For example, a ReplicaSet is the owner of a set of Pods. \n",
    "These owned objects are dependents of their owner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://d33wubrfki0l68.cloudfront.net/2475489eaf20163ec0f54ddc1d92aa8d4c87c96b/e7c81/images/docs/components-of-kubernetes.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control Plane Components:\n",
    "- kube-apiserver: The core component server that exposes the Kubernetes HTTP API\n",
    "- etcd: Consistent and highly-available key value store for all API server data\n",
    "- kube-scheduler: Looks for Pods not yet bound to a node, and assigns each Pod to a suitable node.\n",
    "- kube-controller-manager: Runs controllers to implement Kubernetes API behavior.\n",
    "- cloud-controller-manager: Integrates with underlying cloud provider(s).\n",
    "\n",
    "Node Components:\n",
    "- kubelet: Ensures that Pods are running, including their containers.\n",
    "- kube-proxy: Maintains network rules on nodes to implement Services.\n",
    "- Container runtime: Software responsible for running containers.\n",
    "\n",
    "Addons:\n",
    "- DNS: For cluster-wide DNS resolution\n",
    "- Web UI (Dashboard): [General-purpose web UI for Kubernetes clusters](https://github.com/kubernetes/dashboard), For cluster management via a web interface\n",
    "- Container Resource Monitoring: For collecting and storing container metrics\n",
    "- Cluster-level Logging: For saving container logs to a central log store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kubelet\n",
    "- https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kube-proxy\n",
    "- https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kube-apiserver\n",
    "- https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kube-controller-manager\n",
    "- https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kube-scheduler\n",
    "- https://kubernetes.io/docs/reference/command-line-tools-reference/kube-scheduler/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kubernetes Metrics Server\n",
    "\n",
    "https://github.com/kubernetes-sigs/metrics-server\n",
    "\n",
    "> Metrics Server is a scalable, efficient source of container resource metrics for Kubernetes built-in autoscaling pipelines.\n",
    ">\n",
    "> Metrics Server collects resource metrics from Kubelets and exposes them in Kubernetes apiserver through [Metrics API](https://github.com/kubernetes/metrics) for use by [Horizontal Pod Autoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/) and [Vertical Pod Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/). Metrics API can also be accessed by `kubectl top`, making it easier to debug autoscaling pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 容器编排\n",
    "- containers\n",
    "\n",
    "autoscaling workloads:\n",
    "- HorizontalPodAutoscaler(HPA)\n",
    "- VerticalPodAutoscaler(VPA)\n",
    "- Autoscaling based on cluster size\n",
    "- Event driven Autoscaling\n",
    "- Autoscaling based on schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workloads\n",
    "\n",
    "- Pods: 最小部署单元, 一组共享网络和存储的容器\n",
    "\n",
    "- Deployment: 提供声明式更新Pod和ReplicaSet, Pod水平扩展/收缩, 滚动更新, 降级操作\n",
    "\n",
    "A Deployment provides *declarative updates for Pods and ReplicaSets*. You describe a desired state in a Deployment, and the Deployment Controller changes the actual state to the desired state at a controlled rate. You can define Deployments to create new ReplicaSets, or to remove existing Deployments and adopt all their resources with new Deployments.\n",
    "\n",
    "- ReplicaSet(替代ReplicationController): 维护一组运行中的Pod, 对应于应用的版本\n",
    "\n",
    "A ReplicaSet's purpose is to *maintain a stable set of replica Pods running at any given time*. As such, it is often used to guarantee the availability of a specified number of identical Pods.\n",
    "\n",
    "- StatefulSets: 直接管理Pod\n",
    "  - 拓扑状态: Headleass Service(clusterIp = None)在DNS中生成有编号Pod相应记录.\n",
    "  - 存储状态: 为每个Pod分配并创建一个相同编号的PVC\n",
    "\n",
    "StatefulSet is the workload API object used to *manage stateful applications*. Manages the deployment and scaling of a set of Pods, and provides *guarantees about the ordering and uniqueness of these Pods*. Like a Deployment, a StatefulSet manages Pods that are based on an identical container spec. Unlike a Deployment, a StatefulSet maintains a sticky **identity** for each of their Pods. These pods are created from the same spec, but are not interchangeable: each has a persistent identifier that it maintains across any rescheduling. If you want to use storage volumes to provide persistence for your workload, you can use a StatefulSet as part of the solution. Although individual Pods in a StatefulSet are susceptible to failure, the persistent Pod identifiers make it easier to match existing volumes to the new Pods that replace any that have failed.\n",
    "\n",
    "\n",
    "- DaemonSet: 确保在所有/部分Node上运行一个Pod拷贝\n",
    "\n",
    "A DaemonSet ensures that *all (or some) Nodes run a copy of a Pod*. As nodes are added to the cluster, Pods are added to them. As nodes are removed from the cluster, those Pods are garbage collected. Deleting a DaemonSet will clean up the Pods it created.\n",
    "\n",
    "Some typical uses of a DaemonSet are:\n",
    "\n",
    "running a cluster storage daemon on every node\n",
    "running a logs collection daemon on every node\n",
    "running a node monitoring daemon on every node\n",
    "In a simple case, one DaemonSet, covering all nodes, would be used for each type of daemon. A more complex setup might use multiple DaemonSets for a single type of daemon, but with different flags and/or different memory and cpu requests for different hardware types.\n",
    "\n",
    "- Jobs: 确保Pod可靠的运行完成.\n",
    "\n",
    "A Job creates one or more Pods and will *continue to retry execution of the Pods until a specified number of them successfully terminate*. As pods successfully complete, the Job tracks the successful completions. When a specified number of successful completions is reached, the task (ie, Job) is complete. Deleting a Job will clean up the Pods it created. Suspending a Job will delete its active Pods until the Job is resumed again.\n",
    "\n",
    "A simple case is to create one Job object in order to reliably run one Pod to completion. The Job object will start a new Pod if the first Pod fails or is deleted (for example due to a node hardware failure or a node reboot).\n",
    "\n",
    "You can also use a Job to run multiple Pods in parallel.\n",
    "\n",
    "If you want to run a Job (either a single task, or several in parallel) on a schedule, see CronJob.\n",
    "\n",
    "- Automatic Cleanup for Finished Jobs\n",
    "\n",
    "> FEATURE STATE: Kubernetes v1.23 [stable]\n",
    "\n",
    "When your Job has finished, it's useful to keep that Job in the API (and not immediately delete the Job) so that you can tell whether the Job succeeded or failed.\n",
    "\n",
    "Kubernetes' TTL-after-finished controller provides a TTL (time to live) mechanism to limit the lifetime of Job objects that have finished execution.\n",
    "\n",
    "- CronJob: 重复调度的Job.\n",
    "\n",
    "> FEATURE STATE: Kubernetes v1.21 [stable]\n",
    "\n",
    "A CronJob creates Jobs on a *repeating schedule*.\n",
    "\n",
    "CronJob is meant for performing regular scheduled actions such as backups, report generation, and so on. One CronJob object is like one line of a crontab (cron table) file on a Unix system. It runs a job periodically on a given schedule, written in Cron format.\n",
    "\n",
    "- ReplicationController\n",
    "\n",
    "> Note: A Deployment that configures a ReplicaSet is now the recommended way to set up replication.\n",
    "\n",
    "A ReplicationController ensures that a specified number of pod replicas are running at any one time. In other words, a ReplicationController makes sure that a pod or a homogeneous set of pods is always up and available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRI\n",
    "\n",
    "The CRI is a plugin interface which enables the kubelet to use a wide variety of container runtimes, without having a need to recompile the cluster components.\n",
    "    \n",
    "The Kubernetes Container Runtime Interface (CRI) defines the main gRPC protocol for the communication between the cluster components kubelet and container runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络\n",
    "- service, load balancing, networking\n",
    "- Network plugins: CNI\n",
    "- [Ports and Protocols](https://kubernetes.io/docs/reference/networking/ports-and-protocols/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "容器跨主机通信: 例Flannel框架\n",
    "* UDP: 三层覆盖网络\n",
    "* host-gw: 将每个Flannel子网下一条设置成该子网的宿主机IP(主机重放容器通信链路的网关)\n",
    "* VXLAN: 虚拟可扩展局域网, 在三层覆盖网络上覆盖一层虚拟的由内核VXLAN模块维护的二层网络, 模拟出主机在局域网中."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络隔离: API对象NetworkPolicy\n",
    "* podSelector\n",
    "* ingress\n",
    "* egress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Service: 暴露以一组Pod方式运行的引用作为网络服务, 同时提供负载均衡\n",
    "- 服务的Endpoint: 被selector选中的Pod(处于Running状态, readinessProbe通过)\n",
    "\n",
    "An abstract way to expose an application running on a set of `Pod`s as a network service.\n",
    "\n",
    "With Kubernetes you don't need to modify your application to use an unfamiliar service discovery mechanism. Kubernetes gives Pods their own IP addresses and a single DNS name for a set of Pods, and can load-balance across them.\n",
    "\n",
    "- Ingress: Service的Service, 一个全局的负载均衡器.\n",
    "\n",
    "FEATURE STATE: Kubernetes v1.19 [stable]\n",
    "\n",
    "An API object that manages external access to the services in a cluster, typically HTTP.\n",
    "\n",
    "Ingress may provide load balancing, SSL termination and name-based virtual hosting.\n",
    "\n",
    "![Ingress](https://d33wubrfki0l68.cloudfront.net/91ace4ec5dd0260386e71960638243cf902f8206/c3c52/docs/images/ingress.svg)\n",
    "\n",
    "- Ingress Controllers\n",
    "\n",
    "In order for the Ingress resource to work, the cluster must have an ingress controller running.\n",
    "\n",
    "Unlike other types of controllers which run as part of the `kube-controller-manager` binary, Ingress controllers are not started automatically with a cluster. Use this page to choose the ingress controller implementation that best fits your cluster.\n",
    "\n",
    "Kubernetes as a project supports and maintains AWS, GCE, and nginx ingress controllers.\n",
    "\n",
    "Additional third-party controllers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "服务被访问: P.122\n",
    "* VIP\n",
    "* DNS\n",
    "  * Normal: VIP, my-svc-ns.svc.cluster.local\n",
    "  * Headleass: 代理的某个Pod的IP\n",
    "\n",
    "实现Service: P.294\n",
    "* kube-proxy + iptables\n",
    "* 模式\n",
    "  * ClusterIP: VIP, 代理端口, 轮询\n",
    "  * IPVS: 阶段iptables规则过多的问题, 使用Linux IPVS模块\n",
    "    * 在host上创建虚拟网卡kube-ipvs0, 分配VIP, kubelet设置IPVS虚拟主机, 负责轮询负载均衡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从外界访问Service: P.299\n",
    "* NodePort: 宿主机的IP\n",
    "* LoadBalancer: 公有云提供的K8S服务, 使用CloudProvider转接层\n",
    "* ExternalName: kube-dns中添加域名记录\n",
    "* 分配公有IP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 存储\n",
    "- CSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PV: 描述持久化存储的数据卷.\n",
    "\n",
    "PVC: 描述Pod所希望使用的持久化存储的属性."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 资源管理, 调度\n",
    "- scheduling, preemption, eviction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "控制器: 控制循环\n",
    "\n",
    "API对象: Group, Version, Resource - P.175\n",
    "\n",
    "自定义资源: CRD(Custom Resource Definition)\n",
    "\n",
    "Operator - P.204\n",
    "* 利用自定义资源描述要部署的有状态引用, 之后在自定义控制器中根据自定义API对象的变化来完成具体的部署和运维工作."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 集群管理\n",
    "- node关闭和自动扩展\n",
    "- 证书\n",
    "- 集群网络\n",
    "- 日志\n",
    "- 组件metrics\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日志\n",
    "- [System Logs](https://kubernetes.io/docs/concepts/cluster-administration/system-logs/)\n",
    "- [kube-log-runner](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/component-base/logs/kube-log-runner/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置\n",
    "- ConfigMap\n",
    "- Secrets\n",
    "- liveness, readiness, startup probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kubelet uses **liveness probes** to know when to restart a container. \n",
    "For example, liveness probes could catch a deadlock, where an application is running, but unable to make progress. Restarting a container in such a state can help to make the application more available despite bugs.\n",
    "\n",
    "The kubelet uses **readiness probes** to know when a container is ready to start accepting traffic. \n",
    "A Pod is considered ready when all of its containers are ready. One use of this signal is to control which Pods are used as backends for Services. When a Pod is not ready, it is removed from Service load balancers.\n",
    "\n",
    "The kubelet uses **startup probes** to know when a container application has started. \n",
    "If such a probe is configured, it disables liveness and readiness checks until it succeeds, making sure those probes don't interfere with the application startup. This can be used to adopt liveness checks on slow starting containers, avoiding them getting killed by the kubelet before they are up and running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Security, Policy\n",
    "\n",
    "Security:\n",
    "- Pod security: standards, admission, policy\n",
    "- Service account\n",
    "- API access\n",
    "- RBAC\n",
    "\n",
    "Policy:\n",
    "- resource quota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 扩展Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Docker Desktop Kubernetes](https://docs.docker.com/desktop/features/kubernetes/): ex v1.27.2\n",
    "- GoogleContainerTools\n",
    "\t- [distroless](https://github.com/GoogleContainerTools/distroless): Language focused docker images, minus the operating system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kubectl\n",
    "- [The Kubectl book](https://kubectl.docs.kubernetes.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Version: version.Info{Major:\"1\", Minor:\"27\", GitVersion:\"v1.27.2\", GitCommit:\"7f6f68fdabc4df88cfea2dcf9a19b2b830f1e647\", GitTreeState:\"clean\", BuildDate:\"2023-05-17T14:20:07Z\", GoVersion:\"go1.20.4\", Compiler:\"gc\", Platform:\"windows/amd64\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kustomize Version: v5.0.1\n",
      "Server Version: version.Info{Major:\"1\", Minor:\"27\", GitVersion:\"v1.27.2\", GitCommit:\"7f6f68fdabc4df88cfea2dcf9a19b2b830f1e647\", GitTreeState:\"clean\", BuildDate:\"2023-05-17T14:13:28Z\", GoVersion:\"go1.20.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
     ]
    }
   ],
   "source": [
    "!kubectl version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME             STATUS   ROLES           AGE   VERSION\n",
      "docker-desktop   Ready    control-plane   33d   v1.27.2\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME              STATUS   AGE\n",
      "default           Active   33d\n",
      "kube-node-lease   Active   33d\n",
      "kube-public       Active   33d\n",
      "kube-system       Active   33d\n"
     ]
    }
   ],
   "source": [
    "!kubectl get ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Client\n",
    "- [client libraries](https://kubernetes.io/docs/reference/using-api/client-libraries/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kubernetes in d:\\software\\miniconda3\\lib\\site-packages (32.0.1)\n",
      "Requirement already satisfied: certifi>=14.05.14 in d:\\software\\miniconda3\\lib\\site-packages (from kubernetes) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\software\\miniconda3\\lib\\site-packages (from kubernetes) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\software\\miniconda3\\lib\\site-packages (from kubernetes) (2.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in d:\\software\\miniconda3\\lib\\site-packages (from kubernetes) (6.0.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in d:\\software\\miniconda3\\lib\\site-packages (from kubernetes) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\software\\miniconda3\\lib\\site-packages (from kubernetes) (1.8.0)\n",
      "Requirement already satisfied: requests in d:\\software\\miniconda3\\lib\\site-packages (from kubernetes) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in d:\\software\\miniconda3\\lib\\site-packages (from kubernetes) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in d:\\software\\miniconda3\\lib\\site-packages (from kubernetes) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in d:\\software\\miniconda3\\lib\\site-packages (from kubernetes) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in d:\\software\\miniconda3\\lib\\site-packages (from kubernetes) (0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\software\\miniconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\software\\miniconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\software\\miniconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\software\\miniconda3\\lib\\site-packages (from requests->kubernetes) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\software\\miniconda3\\lib\\site-packages (from requests->kubernetes) (3.7)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\software\\miniconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install kubernetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing pods with their IPs:\n",
      "10.1.0.46\tkube-system\tcoredns-5d78c9869d-rlgnm\n",
      "10.1.0.49\tkube-system\tcoredns-5d78c9869d-zkbjr\n",
      "192.168.65.4\tkube-system\tetcd-docker-desktop\n",
      "192.168.65.4\tkube-system\tkube-apiserver-docker-desktop\n",
      "192.168.65.4\tkube-system\tkube-controller-manager-docker-desktop\n",
      "192.168.65.4\tkube-system\tkube-proxy-plbl4\n",
      "192.168.65.4\tkube-system\tkube-scheduler-docker-desktop\n",
      "10.1.0.47\tkube-system\tstorage-provisioner\n",
      "10.1.0.48\tkube-system\tvpnkit-controller\n",
      "docker-desktop\n",
      "default\n",
      "kube-node-lease\n",
      "kube-public\n",
      "kube-system\n",
      "pod: coredns-5d78c9869d-rlgnm\n",
      "\n",
      "pod: coredns-5d78c9869d-zkbjr\n",
      "\n",
      "pod: etcd-docker-desktop\n",
      "Running\n",
      "ook\":\"433.362µs\",\"hash\":4221830778}\n",
      "{\"level\":\"info\",\"ts\":\"2025-02-24T03:04:09.288Z\",\"caller\":\"mvcc/hash.go:137\",\"msg\":\"storing new hash\",\"hash\":4221830778,\"revision\":267628,\"compact-revision\":267230}\n",
      "\n",
      "\n",
      "pod: kube-apiserver-docker-desktop\n",
      "\n",
      "pod: kube-controller-manager-docker-desktop\n",
      "\n",
      "pod: kube-proxy-plbl4\n",
      "\n",
      "pod: kube-scheduler-docker-desktop\n",
      "\n",
      "pod: storage-provisioner\n",
      "\n",
      "pod: vpnkit-controller\n",
      "\n",
      "service: kube-dns\n"
     ]
    }
   ],
   "source": [
    "# Access Clusters Using the Kubernetes API\n",
    "# https://kubernetes.io/docs/tasks/administer-cluster/access-cluster-api/\n",
    "\n",
    "# kubernetes.client\n",
    "# https://github.com/kubernetes-client/python/blob/master/kubernetes/README.md\n",
    "from kubernetes import client, config\n",
    "import pprint\n",
    "\n",
    "config.load_kube_config()\n",
    "\n",
    "v1 = client.CoreV1Api()\n",
    "print(\"Listing pods with their IPs:\")\n",
    "ret = v1.list_pod_for_all_namespaces(watch=False)\n",
    "for i in ret.items:\n",
    "  print(\"%s\\t%s\\t%s\" % (i.status.pod_ip, i.metadata.namespace, i.metadata.name))\n",
    "\n",
    "# nodes\n",
    "nodes = v1.list_node()\n",
    "for item in nodes.items:\n",
    "  print(item.metadata.name)\n",
    "\n",
    "# namespaces\n",
    "namespaces = v1.list_namespace()\n",
    "for item in namespaces.items:\n",
    "  print(item.metadata.name)\n",
    "\n",
    "# pods\n",
    "ns_name = 'kube-system'\n",
    "pods = v1.list_namespaced_pod(ns_name)\n",
    "for item in pods.items:\n",
    "  pod_name = item.metadata.name\n",
    "  print(\"pod:\", pod_name)\n",
    "  if 'etcd-docker-desktop' == pod_name:\n",
    "    print(v1.read_namespaced_pod_status(pod_name, ns_name).status.phase)\n",
    "    print(v1.read_namespaced_pod_log(pod_name, ns_name)[-200:])\n",
    "  print()\n",
    "\n",
    "# services\n",
    "ns_name = 'kube-system'\n",
    "services = v1.list_namespaced_service(ns_name)\n",
    "for item in services.items:\n",
    "  srv_name = item.metadata.name\n",
    "  print(\"service:\", srv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minikube\n",
    "- https://github.com/kubernetes/minikube\n",
    "\n",
    "> minikube implements a local Kubernetes cluster on macOS, Linux, and Windows. minikube's [primary goals](https://minikube.sigs.k8s.io/docs/concepts/principles/) are to be the best tool for local Kubernetes application development and to support all Kubernetes features that fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'minikube.exe' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# !docker pull gcr.io/k8s-minikube/storage-provisioner:v5\n",
    "# !docker pull registry.k8s.io/kube-controller-manager:v1.32.0\n",
    "# !docker pull registry.k8s.io/coredns/coredns:v1.11.3\n",
    "# !docker pull registry.k8s.io/kube-apiserver:v1.32.0\n",
    "# !docker pull registry.k8s.io/kube-proxy:v1.32.0\n",
    "# !docker pull registry.k8s.io/pause:3.10\n",
    "# !docker pull registry.k8s.io/etcd:3.5.16-0\n",
    "# !docker pull registry.k8s.io/kube-scheduler:v1.32.0\n",
    "\n",
    "!minikube delete\n",
    "!minikube config set driver docker\n",
    "# https://github.com/kubernetes/minikube/issues/8997\n",
    "# https://storage.googleapis.com/minikube-preloaded-volume-tarballs/v18/v1.32.0/preloaded-images-k8s-v18-v1.32.0-docker-overlay2-amd64.tar.lz4?checksum=md5:4da2ed9bc13e09e8e9b7cf53d01335db\n",
    "\n",
    "!minikube start --alsologtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minikube\n",
      "type: Control Plane\n",
      "host: Running\n",
      "kubelet: Running\n",
      "apiserver: Running\n",
      "kubeconfig: Configured\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!minikube status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !minikube dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application\n",
    "- quarkus-kubernets in 'Reactive Systems in Java'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jib\n",
    "- [Code](https://github.com/GoogleContainerTools/jib)\n",
    "\n",
    "> Jib: Build container images for your Java applications.\n",
    "> \n",
    "> Jib builds optimized Docker and [OCI](https://github.com/opencontainers/image-spec) images for your Java applications without a Docker daemon - and without deep mastery of Docker best-practices. It is available as plugins for [Maven](https://github.com/GoogleContainerTools/jib/blob/master/jib-maven-plugin) and [Gradle](https://github.com/GoogleContainerTools/jib/blob/master/jib-gradle-plugin) and as a Java library.\n",
    ">\n",
    ">- [Maven](https://maven.apache.org/): See documentation for [jib-maven-plugin](https://github.com/GoogleContainerTools/jib/blob/master/jib-maven-plugin).\n",
    ">- [Gradle](https://gradle.org/): See documentation for [jib-gradle-plugin](https://github.com/GoogleContainerTools/jib/blob/master/jib-gradle-plugin).\n",
    ">- [Jib Core](https://github.com/GoogleContainerTools/jib/blob/master/jib-core): A general-purpose container-building library for Java.\n",
    ">- [Jib CLI](https://github.com/GoogleContainerTools/jib/blob/master/jib-cli): A command-line interface for building images that uses Jib Core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maven Plugin:\n",
    "\n",
    "```xml\n",
    "<properties>\n",
    "    <app.main.class>xxx</app.main.class>\n",
    "    <jib.image.from>\n",
    "    docker://eclipse-temurin:17-jdk-alpine@sha256:ddd7a05cf8263989c29f2a9476dcfa25d0eaf8310d400f998ebd03c0d32feb72\n",
    "    </jib.image.from>\n",
    "    <jib.image.to>projectxxx/${project.artifactId}:${project.version}</jib.image.to>\n",
    "    <harbor.username>xxx</harbor.username>\n",
    "    <harbor.password>xxx</harbor.password>\n",
    "</properties>\n",
    "\n",
    "<plugin>\n",
    "    <groupId>com.google.cloud.tools</groupId>\n",
    "    <artifactId>jib-maven-plugin</artifactId>\n",
    "    <version>3.3.2</version>\n",
    "    <configuration>\n",
    "        <containerizingMode>packaged</containerizingMode>\n",
    "        <from>\n",
    "            <image>${jib.image.from}</image>\n",
    "        </from>\n",
    "        <to>\n",
    "            <image>${jib.image.to}</image>\n",
    "            <auth>\n",
    "                <username>${harbor.username}</username>\n",
    "                <password>${harbor.password}</password>\n",
    "            </auth>\n",
    "        </to>\n",
    "        <container>\n",
    "            <jvmFlags>\n",
    "                <jvmFlag>-Xms512m</jvmFlag>\n",
    "            </jvmFlags>\n",
    "            <environment>\n",
    "                <TZ>Asia/Shanghai</TZ>\n",
    "                <!-- profile -->\n",
    "                <!-- <spring.profiles.active>prod</spring.profiles.active>-->\n",
    "            </environment>\n",
    "            <volumes>\n",
    "                <volume>/tmp</volume>\n",
    "            </volumes>\n",
    "            <ports>\n",
    "                <port>80</port>\n",
    "            </ports>\n",
    "            <!-- <entrypoint>java -cp /app/libs/* -jar /app/${project.artifactId}-${project.version}.jar-->\n",
    "            <!-- </entrypoint>-->\n",
    "            <mainClass>${app.main.class}</mainClass>\n",
    "            <format>OCI</format>\n",
    "        </container>\n",
    "        <allowInsecureRegistries>true</allowInsecureRegistries>\n",
    "    </configuration>\n",
    "</plugin>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCI: Open Container Initiative\n",
    "\n",
    "\n",
    "- [About the Open Container Initiative](https://opencontainers.org/about/overview/)\n",
    "\n",
    "> Open Container Initiative (OCI) \n",
    "> The Open Container Initiative (OCI) is a lightweight, open governance structure (project), formed under the auspices of the Linux Foundation, for the express purpose of creating open industry standards around container formats and runtimes. The OCI was launched on June 22nd 2015 by Docker, CoreOS and other leaders in the container industry.\n",
    "> \n",
    "> The OCI currently contains three specifications: **the Runtime Specification (runtime-spec)**, **the Image Specification (image-spec)** and **the Distribution Specification (distribution-spec)**. The Runtime Specification outlines how to run a “filesystem bundle” that is unpacked on disk. At a high-level an OCI implementation would download an OCI Image then unpack that image into an OCI Runtime filesystem bundle. At this point the OCI Runtime Bundle would be run by an OCI Runtime.\n",
    "> \n",
    "> This entire workflow should support the UX that users have come to expect from container engines like **Docker** and **rkt**: primarily, the ability to run an image with no additional arguments:\n",
    ">\n",
    ">- docker run example.com/org/app:v1.0.0\n",
    ">- rkt run example.com/org/app,version=v1.0.0\n",
    ">\n",
    "> To support this UX the OCI Image Format contains sufficient information to launch the application on the target platform (e.g. command, arguments, environment variables, etc). This specification defines how to create an OCI Image, which will generally be done by a build system, and output an **image manifest**, a **filesystem (layer) serialization**, and an **image configuration**.\n",
    "> \n",
    "> Docker is donating its container format and runtime, **runC**, to the OCI to serve as the cornerstone of this new effort. It is available now at https://github.com/opencontainers/runc.\n",
    "> \n",
    "> The distribution specification reached v1.0 in May 2020 and was introduced to OCI as an effort to standardize the API to distribute container images. However, the specification is designed generically enough to be leveraged as a distribution mechanism for any type of content.\n",
    "\n",
    "\n",
    "Specifications:\n",
    "- [OCI Runtime Specification](https://github.com/opencontainers/runtime-spec)\n",
    "- [OCI Image Format](https://github.com/opencontainers/image-spec)\n",
    "- [OCI Distribution Specification](https://github.com/opencontainers/distribution-spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Kubernetes API Reference: https://kubernetes.io/docs/reference/kubernetes-api\n",
    " - API Conventions: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md\n",
    " - One-page API Reference for Kubernetes v1.28: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.28/\n",
    "\n",
    "Configuration APIs: https://kubernetes.io/docs/reference/config-api/\n",
    " - kubeconfig\n",
    " - kube-apiserver admission\n",
    " - kube-apiserver configuration\n",
    " - kube-apiserver encryption\n",
    " - kube-apiserver event rate limit\n",
    " - kubelet configuration\n",
    " - kubelet credential providers, kube-scheduler configuration\n",
    " - kube-controller-manager configuration\n",
    " - kube-proxy configuration\n",
    " - audit.k8s.io API\n",
    " - Client authentication API\n",
    " - WebhookAdmission configuration\n",
    " - ImagePolicy API\n",
    "\n",
    "Design Docs\n",
    " - Kubernetes Architecture: https://git.k8s.io/design-proposals-archive/architecture/architecture.md\n",
    " - Kubernetes Design Overview: https://git.k8s.io/design-proposals-archive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
